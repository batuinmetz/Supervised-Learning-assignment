{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "338be92a-dfbb-4d07-81fe-0571c2beb41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  67.45718050065877 %\n",
      "Execution time in seconds: 0.17966318130493164\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "##data loaded\n",
    "data=pd.read_csv('chocolate_bars.csv',index_col=0)\n",
    "data.head(-5)\n",
    "##filing the missing datas\n",
    "#filling the missing tables with the most common ingredients\n",
    "data['ingredients'].fillna(data['ingredients'].mode()[0], inplace=True)\n",
    "data['num_ingredients'].fillna(data['num_ingredients'].mode()[0], inplace=True)\n",
    "#print(data)\n",
    "\n",
    "# Importing LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Instantiating LabelEncoder\n",
    "le=LabelEncoder()\n",
    "# Iterating over all the values of each column and extract their dtypes\n",
    "for col in data.columns.to_numpy():\n",
    "    # Comparing if the dtype is object\n",
    "    if data[col].dtypes in ('object','category'):\n",
    "    # Using LabelEncoder to do the numeric transformation\n",
    "        data[col]=le.fit_transform(data[col].astype(str))\n",
    "        \n",
    "#Binning the rating column\n",
    "cut_labels = ['really bad', 'bad', 'ok', 'good']\n",
    "cut_bins = [0, 0.99,1.99,2.99,4.0]\n",
    "data['rating'] = pd.cut(data['rating'], bins=cut_bins, labels=cut_labels)\n",
    "\n",
    "#creating the testing and training variables\n",
    "x=data.drop(\"rating\",axis=1)\n",
    "y=data[\"rating\"]\n",
    "#print(y)\n",
    "#print(x)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42,stratify=y)\n",
    "x_train.shape, x_test.shape\n",
    "\n",
    "#validation curve\n",
    "'''\n",
    "k=np.arange(1,100)\n",
    "train_score, test_score = validation_curve(MLPClassifier(), x_train, y_train, param_name='hidden_layer_sizes', param_range=k, scoring=\"accuracy\",cv=5)\n",
    "plt.plot(k, train_score.mean(axis=1),marker='o', markersize=5,color='blue', label='Training Accuracy')\n",
    "plt.plot(k, test_score.mean(axis=1),marker='o', markersize=5,color='green', label='Validation Accuracy')\n",
    "plt.xlabel('hidden_layer_sizes')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "'''\n",
    "#learning curve\n",
    "train_size, train_score2, test_score2=learning_curve(MLPClassifier(activation='relu',random_state=42, learning_rate_init=0.001, max_iter=200, hidden_layer_sizes=90), x_train, y_train, train_sizes=np.linspace(0.1, 1.0, 10), scoring=\"accuracy\",cv=5)\n",
    "train_mean = np.mean(train_score2, axis=1)\n",
    "test_mean = np.mean(test_score2, axis=1)\n",
    "train_std = np.std(train_score2, axis=1)\n",
    "test_std = np.std(test_score2, axis=1)\n",
    "plt.plot(train_size, train_mean, color='blue', marker='o', markersize=5, label='Training Accuracy')\n",
    "plt.fill_between(train_size, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_size, test_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation Accuracy')\n",
    "plt.fill_between(train_size, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Model accuracy')\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "#Neural network\n",
    "import time\n",
    "startTime = time.time()\n",
    "clf =MLPClassifier(activation='relu',random_state=42, learning_rate_init=0.001, max_iter=200, hidden_layer_sizes=90).fit(x_train, y_train)\n",
    "#print(\"Training set score: %f\" % clf.score(x, y))\n",
    "#print(\"Training set loss: %f\" % clf.loss_)\n",
    "#plt.plot(clf.loss_curve_)\n",
    "\n",
    "#Evaluate the accuracy of the model\n",
    "y_pred = clf.predict(x_test)\n",
    "predictions = metrics.accuracy_score(y_test, y_pred)\n",
    "#Calculating the accuracy in percentage\n",
    "print('The accuracy is: ', predictions * 100, '%')\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f34ccd-0c5c-458f-86aa-304c5960542e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bcd8fd-567a-4977-81a5-8a2c5ed21ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
